Title: relu_with_scaled_sigmoid_adam_0.0005 


_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_1 (InputLayer)         (None, 75, 100, 1)        0         
_________________________________________________________________
conv_1_1 (Conv2D)            (None, 73, 98, 32)        320       
_________________________________________________________________
conv_1_2 (Conv2D)            (None, 71, 96, 32)        9248      
_________________________________________________________________
pool_1_2 (MaxPooling2D)      (None, 35, 48, 32)        0         
_________________________________________________________________
conv_2_1 (Conv2D)            (None, 33, 46, 64)        18496     
_________________________________________________________________
conv_2_2 (Conv2D)            (None, 31, 44, 64)        36928     
_________________________________________________________________
conv_2_3 (Conv2D)            (None, 29, 42, 64)        36928     
_________________________________________________________________
pool_2_3 (MaxPooling2D)      (None, 14, 21, 64)        0         
_________________________________________________________________
conv_3_1 (Conv2D)            (None, 12, 19, 128)       73856     
_________________________________________________________________
conv_3_2 (Conv2D)            (None, 10, 17, 128)       147584    
_________________________________________________________________
conv_3_3 (Conv2D)            (None, 8, 15, 128)        147584    
_________________________________________________________________
pool_3_3 (MaxPooling2D)      (None, 4, 7, 128)         0         
_________________________________________________________________
flatten_3_3 (Flatten)        (None, 3584)              0         
_________________________________________________________________
dense_4_1 (Dense)            (None, 2048)              7342080   
_________________________________________________________________
dense_4_2 (Dense)            (None, 1024)              2098176   
_________________________________________________________________
dense_4_3 (Dense)            (None, 128)               131200    
_________________________________________________________________
dense_4_4 (Dense)            (None, 1)                 129       
_________________________________________________________________
output (ScaleLayer)          (None, 1)                 0         
=================================================================
Total params: 10,042,529
Trainable params: 10,042,529
Non-trainable params: 0
_________________________________________________________________

           Optimizer : Adam
_________________________________________________________________

                  lr : 0.000500
              beta_1 : 0.900000
              beta_2 : 0.999000
               decay : 0.0
             amsgrad : False
             epsilon : 1e-07
       initial_decay : 0.0
_________________________________________________________________

       Loss Function : loss
_________________________________________________________________

            Metric 0 : mae
            Metric 1 : accuracy
_________________________________________________________________

Train on 640 samples, validate on 160 samples
Epoch 1/10

250/640 [==========>...................] - ETA: 5s - loss: 3.7826 - mean_absolute_error: 0.0151 - accuracy: 0.8487
500/640 [======================>.......] - ETA: 1s - loss: 20.5152 - mean_absolute_error: 0.0821 - accuracy: 0.4252
640/640 [==============================] - 5s 7ms/step - loss: 16.4182 - mean_absolute_error: 0.0669 - accuracy: 0.5232 - val_loss: 1.9382 - val_mean_absolute_error: 0.0121 - val_accuracy: 0.8789
Epoch 2/10

250/640 [==========>...................] - ETA: 0s - loss: 3.0231 - mean_absolute_error: 0.0121 - accuracy: 0.8791
500/640 [======================>.......] - ETA: 0s - loss: 3.5402 - mean_absolute_error: 0.0142 - accuracy: 0.8588
640/640 [==============================] - 1s 949us/step - loss: 3.6639 - mean_absolute_error: 0.0175 - accuracy: 0.8258 - val_loss: 2.3553 - val_mean_absolute_error: 0.0147 - val_accuracy: 0.8531
Epoch 3/10

250/640 [==========>...................] - ETA: 0s - loss: 3.8849 - mean_absolute_error: 0.0155 - accuracy: 0.8451
500/640 [======================>.......] - ETA: 0s - loss: 4.0069 - mean_absolute_error: 0.0160 - accuracy: 0.8402
640/640 [==============================] - 1s 926us/step - loss: 3.5529 - mean_absolute_error: 0.0155 - accuracy: 0.8450 - val_loss: 1.9150 - val_mean_absolute_error: 0.0120 - val_accuracy: 0.8803
Epoch 4/10

250/640 [==========>...................] - ETA: 0s - loss: 2.8202 - mean_absolute_error: 0.0113 - accuracy: 0.8872
500/640 [======================>.......] - ETA: 0s - loss: 3.0525 - mean_absolute_error: 0.0122 - accuracy: 0.8779
640/640 [==============================] - 1s 948us/step - loss: 2.7500 - mean_absolute_error: 0.0121 - accuracy: 0.8785 - val_loss: 1.6502 - val_mean_absolute_error: 0.0103 - val_accuracy: 0.8969
Epoch 5/10

250/640 [==========>...................] - ETA: 0s - loss: 2.5522 - mean_absolute_error: 0.0102 - accuracy: 0.8979
500/640 [======================>.......] - ETA: 0s - loss: 2.4589 - mean_absolute_error: 0.0098 - accuracy: 0.9017
640/640 [==============================] - 1s 932us/step - loss: 2.3312 - mean_absolute_error: 0.0106 - accuracy: 0.8939 - val_loss: 1.5419 - val_mean_absolute_error: 0.0096 - val_accuracy: 0.9036
Epoch 6/10

250/640 [==========>...................] - ETA: 0s - loss: 2.6176 - mean_absolute_error: 0.0105 - accuracy: 0.8953
500/640 [======================>.......] - ETA: 0s - loss: 2.7566 - mean_absolute_error: 0.0110 - accuracy: 0.8898
640/640 [==============================] - 1s 943us/step - loss: 2.6139 - mean_absolute_error: 0.0119 - accuracy: 0.8811 - val_loss: 2.7678 - val_mean_absolute_error: 0.0173 - val_accuracy: 0.8270
Epoch 7/10

250/640 [==========>...................] - ETA: 0s - loss: 3.9341 - mean_absolute_error: 0.0157 - accuracy: 0.8426
500/640 [======================>.......] - ETA: 0s - loss: 3.1681 - mean_absolute_error: 0.0127 - accuracy: 0.8733
640/640 [==============================] - 1s 965us/step - loss: 2.8913 - mean_absolute_error: 0.0129 - accuracy: 0.8714 - val_loss: 2.0119 - val_mean_absolute_error: 0.0126 - val_accuracy: 0.8744
Epoch 8/10

250/640 [==========>...................] - ETA: 0s - loss: 3.4902 - mean_absolute_error: 0.0140 - accuracy: 0.8606
500/640 [======================>.......] - ETA: 0s - loss: 3.1137 - mean_absolute_error: 0.0125 - accuracy: 0.8756
640/640 [==============================] - 1s 934us/step - loss: 2.7739 - mean_absolute_error: 0.0122 - accuracy: 0.8785 - val_loss: 1.9313 - val_mean_absolute_error: 0.0121 - val_accuracy: 0.8793
Epoch 9/10

250/640 [==========>...................] - ETA: 0s - loss: 2.7690 - mean_absolute_error: 0.0111 - accuracy: 0.8892
500/640 [======================>.......] - ETA: 0s - loss: 2.8690 - mean_absolute_error: 0.0115 - accuracy: 0.8853
640/640 [==============================] - 1s 934us/step - loss: 2.5305 - mean_absolute_error: 0.0110 - accuracy: 0.8897 - val_loss: 1.6376 - val_mean_absolute_error: 0.0102 - val_accuracy: 0.8977
Epoch 10/10

250/640 [==========>...................] - ETA: 0s - loss: 2.5476 - mean_absolute_error: 0.0102 - accuracy: 0.8981
500/640 [======================>.......] - ETA: 0s - loss: 2.6438 - mean_absolute_error: 0.0106 - accuracy: 0.8943
640/640 [==============================] - 1s 923us/step - loss: 2.3601 - mean_absolute_error: 0.0104 - accuracy: 0.8964 - val_loss: 1.6030 - val_mean_absolute_error: 0.0100 - val_accuracy: 0.8998
Saving model:model_000.h5



Loss:  2.14106
Accuracy:  89.2946958542 %
