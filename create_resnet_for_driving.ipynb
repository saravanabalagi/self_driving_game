{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Load Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.1 Import images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scripts.deepgtav.messages import frame2numpy\n",
    "import numpy as np\n",
    "import pickle\n",
    "import bunch\n",
    "import gzip\n",
    "import os\n",
    "import cv2\n",
    "\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# open the file\n",
    "filepath = os.path.join(os.getcwd(), 'data')\n",
    "filename = \"dataset_mini.pz\"\n",
    "pfile = gzip.open(os.path.join(filepath, filename), mode='rb')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.2 PCA Function for dimensionality reduction on images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_pca(image, dim=10):\n",
    "    image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "    image = np.matrix(image)\n",
    "    U, S, V = np.linalg.svd(image)\n",
    "    reconst = np.matrix(U[:, :dim]) * np.diag(S[:dim]) * np.matrix(V[:dim, :])\n",
    "    reconst = reconst[...,None]\n",
    "    return reconst"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.3 Setting extracted data to specific variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "count = 0\n",
    "no_of_channels = 3\n",
    "\n",
    "frames_per_weather = 20000\n",
    "reps_per_weather = 8\n",
    "frames_per_rep = int(frames_per_weather/reps_per_weather)\n",
    "image_size = (100, 75)     # required image size\n",
    "minimap_size = (170, 110)  # current minimaps size\n",
    "\n",
    "images = []\n",
    "minimaps = []\n",
    "outputs = []\n",
    "speeds = []\n",
    "yawRates = []\n",
    "\n",
    "# find resize ratio\n",
    "diff = []\n",
    "diff.append(minimap_size[0] - image_size[0])\n",
    "diff.append(minimap_size[1] - image_size[1])\n",
    "ratio = 1- (np.min(diff) / minimap_size[np.argmin(diff)])\n",
    "\n",
    "while True:\n",
    "    try:\n",
    "        \n",
    "        # Load var from pickle\n",
    "        var = pickle.load(pfile)\n",
    "        \n",
    "        # Skip first n frames\n",
    "        count += 1\n",
    "        # if count<3000: continue\n",
    "            \n",
    "        # Save image, minmap and steering\n",
    "        image = var['frame']\n",
    "        image = cv2.resize(image, (200,150))\n",
    "        image = apply_pca(image, dim=20)\n",
    "        images.append(image)\n",
    "        \n",
    "        minimap = var['map']\n",
    "        minimap = cv2.resize(minimap, (100,75))\n",
    "        minimap = minimap[:,:,:]\n",
    "        minimaps.append(minimap)\n",
    "        \n",
    "        speeds.append(var['speed'])\n",
    "        yawRates.append(var['yawRate'])\n",
    "        outputs.append([var['steering'], var['throttle'], var['brake']])\n",
    "        # outputs.append([var['steering']])\n",
    "        \n",
    "        # Display image\n",
    "        if count % 100 == 0:\n",
    "            plt.subplot(121); plt.imshow(image[:,:,0]); plt.axis('off')\n",
    "            plt.subplot(122); plt.imshow(minimap[:,:,::-1]); plt.axis('off')\n",
    "            plt.show()\n",
    "        \n",
    "        if count == 1: print([image.shape, minimap.shape]); print(var.keys())\n",
    "        if count>5000: break\n",
    "            \n",
    "    except EOFError: break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.4 Clipping steering values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(np.min(y), np.max(y))\n",
    "np.clip(y, -1, 1, out=y)\n",
    "print(np.min(y), np.max(y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.5 Finding previous steering values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pick_last_steering = 8\n",
    "holder = np.zeros((y.shape[0], pick_last_steering))\n",
    "gamma = 0.8\n",
    "for i in range(holder.shape[0]):\n",
    "    count = 0\n",
    "    for j in range(i, i-pick_last_steering, -1):\n",
    "        holder[i][count] = y[j-pick_last_steering]*(j>0)#*(gamma**(j-pick_last_steering))\n",
    "        count += 1\n",
    "print(holder.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "images = np.array(images)\n",
    "minimaps = np.array(minimaps)\n",
    "speeds = np.array(speeds)\n",
    "yawRates = np.array(yawRates)\n",
    "holder = np.array(holder)\n",
    "\n",
    "# Get inputs and outputs\n",
    "# x = {}\n",
    "# x.images = images\n",
    "# x.minimaps = minimaps\n",
    "# x = np.concatenate((images, minimaps), axis=1)\n",
    "# x = [images, minimaps, speeds, yawRates, holder]\n",
    "x = [images, minimaps, holder, speeds, yawRates]\n",
    "\n",
    "x_shape = [entity.shape for entity in x]\n",
    "print('Dataset Shape: x: {} | y: {}'.format(x_shape, y.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Data Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.1 Normalise images to [-1, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print([[np.min(entity), np.max(entity)] for entity in x])\n",
    "if not isinstance(x, np.ndarray): \n",
    "    x_new = [(entity/255 - 0.5) * 2 for i, entity in enumerate(x) if i<2]\n",
    "    if len(x)>=2: x_new = [*x_new, *x[2:]]\n",
    "    x = x_new\n",
    "[[np.min(entity), np.max(entity)] for entity in x]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.2 Data splitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 1\n",
    "np.random.seed(seed)\n",
    "\n",
    "recv = [None for i in range(2*len(x))]\n",
    "from sklearn.model_selection import train_test_split\n",
    "*recv, y_train, y_test = train_test_split(*x, y, test_size=0.2, random_state=np.random, shuffle=True)\n",
    "\n",
    "x_train = recv[::2]\n",
    "x_test = recv[1::2]\n",
    "\n",
    "# print(\"Train Data | Test Data\")\n",
    "# x_train = [x0_train, x1_train]\n",
    "# x_test = [x0_test, x1_test]\n",
    "print((\"{0:^10} | {1:^10}\").format(x_train[0].shape[0], x_test[0].shape[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Building Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.1 Importng relevant libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential, Model\n",
    "from keras.layers import Dense, Dropout, Input\n",
    "from keras.layers import Conv2D, MaxPooling2D, Flatten\n",
    "from keras.layers import BatchNormalization\n",
    "from keras.layers.merge import concatenate\n",
    "from keras.utils import np_utils\n",
    "from keras.optimizers import Adam\n",
    "from keras.metrics import mae\n",
    "from keras.initializers import RandomNormal\n",
    "from keras.regularizers import Regularizer\n",
    "import keras.applications.inception_v3 import InceptionV3\n",
    "\n",
    "from keras import backend\n",
    "backend.set_image_dim_ordering('tf')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.2 Create reusable functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "h_image = x[1].shape[1]\n",
    "w_image = x[1].shape[2]\n",
    "c_image = x[1].shape[3]\n",
    "\n",
    "h_maps = x[1].shape[1]\n",
    "w_maps = x[1].shape[2]\n",
    "c_maps = x[1].shape[3]\n",
    "\n",
    "no_of_classes = y.shape[0]\n",
    "#print(x.shape, y.shape)\n",
    "\n",
    "def evaluate_model(model):\n",
    "    print(\"\\n\\n\")\n",
    "    scores = model.evaluate(x_test, y_test)\n",
    "    print(\"Accuracy: \", scores[1]*100, \"%\")\n",
    "    return scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.3 Create helper functions for building model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bn_relu(image, channel):\n",
    "    # BNORM -> RELU\n",
    "    bnorm = BatchNormalization(channel)(image)\n",
    "    activ = Activation('relu')(bnorm)\n",
    "    return activ\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.3 Create the ResNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
